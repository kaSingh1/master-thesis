{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.utils import shuffle, resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"/home/jupyter-karan_singh/FinalDataset/Stepwords_Clean_FinalDataset_ForModel_V3.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same train and test data\n",
    "def split_df_in_train_test(df):\n",
    "    df = df.reset_index()\n",
    "    split_point = int(np.round(df.shape[0]) * 0.8)\n",
    "    df_train = df.loc[:split_point-1,:]\n",
    "    df_test = df.loc[split_point:,:]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_FE = resample(shuffle(news[(news[\"label\"]==\"links\") & (news[\"Länge\"]<512)], random_state=42), \\\n",
    "         random_state=42, n_samples=n_samples)\n",
    "leanLeft_FE = resample(shuffle(news[(news[\"label\"]==\"halbLinks\") & (news[\"Länge\"]<512)], random_state=42), \\\n",
    "         random_state=42, n_samples=n_samples)\n",
    "center_FE = resample(shuffle(news[(news[\"label\"]==\"central\") & (news[\"Länge\"]<512)], random_state=42), \\\n",
    "         random_state=42, n_samples=n_samples)\n",
    "leanRight_FE = resample(shuffle(news[(news[\"label\"]==\"halbRechts\") & (news[\"Länge\"]<512)], random_state=42), \\\n",
    "         random_state=42, n_samples=n_samples)\n",
    "right_FE = resample(shuffle(news[(news[\"label\"]==\"rechts\") & (news[\"Länge\"]<512)], random_state=42), \\\n",
    "         random_state=42, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([split_df_in_train_test(left_FE)[0], \\\n",
    "    split_df_in_train_test(leanLeft_FE)[0], \\\n",
    "    split_df_in_train_test(center_FE)[0], \\\n",
    "    split_df_in_train_test(leanRight_FE)[0], \\\n",
    "    split_df_in_train_test(right_FE)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  pd.concat([split_df_in_train_test(left_FE)[1], \\\n",
    "    split_df_in_train_test(leanLeft_FE)[1], \\\n",
    "    split_df_in_train_test(center_FE)[1], \\\n",
    "    split_df_in_train_test(leanRight_FE)[1], \\\n",
    "    split_df_in_train_test(right_FE)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[\"NeuGenerierterText_str\"], train[\"label\"]\n",
    "X_test, y_test = test[\"NeuGenerierterText_str\"], test[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating German Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stop-words in /home/jupyter-karan_singh/.local/lib/python3.6/site-packages (2018.7.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "\n",
    "#stop_words = get_stop_words('de')\n",
    "stop_words = get_stop_words('german')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TFIDF vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vec = TfidfVectorizer(stop_words=stop_words, max_features=30000, ngram_range=(1, 2))\n",
    "\n",
    "X_train_bi = bigram_vec.fit_transform(X_train.apply(lambda x: np.str_(x)))\n",
    "X_test_bi = bigram_vec.transform(X_test.apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_vec = TfidfVectorizer(stop_words=stop_words, max_features=30000, ngram_range=(1, 3))\n",
    "\n",
    "X_train_tri = trigram_vec.fit_transform(X_train.apply(lambda x: np.str_(x)))\n",
    "X_test_tri = trigram_vec.transform(X_test.apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder()\n",
    "y_train_enc = label_enc.fit_transform(y_train)\n",
    "y_test_enc = label_enc.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['central', 'halbLinks', 'halbRechts', 'links', 'rechts'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc.inverse_transform([0, 1, 2, 3, 4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [0, 1, 2, 3, 4]\n",
    "target_label = ['central', 'halbLinks', 'halbRechts', 'links', 'rechts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(clf, X_train, X_test, y_train, y_test, label, target_label):\n",
    "    \n",
    "    print(\"Training of the classifier: {} \\n\".format(clf))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Accuracy of the classifier:     \")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Confusion Matrix of the classifier: \\n\")\n",
    "    con_mat = confusion_matrix(y_test, y_pred, labels=label)\n",
    "    print(con_mat)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Classification Report of the classifier: \\n\")\n",
    "    report = classification_report(y_test, y_pred, target_names=target_label)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "svc = LinearSVC()\n",
    "lr = LogisticRegression(multi_class=\"multinomial\", solver=\"saga\")\n",
    "nb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...using with bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best') \n",
      "\n",
      "\n",
      "\n",
      "Accuracy of the classifier:     \n",
      "0.7498333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix of the classifier: \n",
      "\n",
      "[[ 828   55  133  104   80]\n",
      " [  43 1005   58   44   50]\n",
      " [ 157   67  748  125  103]\n",
      " [  65   34   84  972   45]\n",
      " [  74   50   91   39  946]]\n",
      "\n",
      "\n",
      "Classification Report of the classifier: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     central       0.71      0.69      0.70      1200\n",
      "   halbLinks       0.83      0.84      0.83      1200\n",
      "  halbRechts       0.67      0.62      0.65      1200\n",
      "       links       0.76      0.81      0.78      1200\n",
      "      rechts       0.77      0.79      0.78      1200\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.75      0.75      0.75      6000\n",
      "weighted avg       0.75      0.75      0.75      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifier(dt, X_train_bi, X_test_bi, y_train_enc, y_test_enc, label, target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the classifier: BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "\n",
      "\n",
      "Accuracy of the classifier:     \n",
      "0.6188333333333333\n",
      "\n",
      "\n",
      "Confusion Matrix of the classifier: \n",
      "\n",
      "[[668  29 374  94  35]\n",
      " [ 60 786 236  61  57]\n",
      " [210  57 834  38  61]\n",
      " [198  14 249 701  38]\n",
      " [ 84  79 252  61 724]]\n",
      "\n",
      "\n",
      "Classification Report of the classifier: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     central       0.55      0.56      0.55      1200\n",
      "   halbLinks       0.81      0.66      0.73      1200\n",
      "  halbRechts       0.43      0.69      0.53      1200\n",
      "       links       0.73      0.58      0.65      1200\n",
      "      rechts       0.79      0.60      0.68      1200\n",
      "\n",
      "    accuracy                           0.62      6000\n",
      "   macro avg       0.66      0.62      0.63      6000\n",
      "weighted avg       0.66      0.62      0.63      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifier(nb, X_train_bi, X_test_bi, y_train_enc, y_test_enc, label, target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the classifier: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) \n",
      "\n",
      "\n",
      "\n",
      "Accuracy of the classifier:     \n",
      "0.8021666666666667\n",
      "\n",
      "\n",
      "Confusion Matrix of the classifier: \n",
      "\n",
      "[[ 895   38  123   86   58]\n",
      " [  38 1068   34   21   39]\n",
      " [ 148   63  819   90   80]\n",
      " [  60   14   65 1020   41]\n",
      " [  56   41   56   36 1011]]\n",
      "\n",
      "\n",
      "Classification Report of the classifier: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     central       0.75      0.75      0.75      1200\n",
      "   halbLinks       0.87      0.89      0.88      1200\n",
      "  halbRechts       0.75      0.68      0.71      1200\n",
      "       links       0.81      0.85      0.83      1200\n",
      "      rechts       0.82      0.84      0.83      1200\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.80      0.80      0.80      6000\n",
      "weighted avg       0.80      0.80      0.80      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifier(svc, X_train_bi, X_test_bi, y_train_enc, y_test_enc, label, target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "\n",
      "\n",
      "Accuracy of the classifier:     \n",
      "0.7506666666666667\n",
      "\n",
      "\n",
      "Confusion Matrix of the classifier: \n",
      "\n",
      "[[ 850   42  153   96   59]\n",
      " [  45 1014   53   30   58]\n",
      " [ 172   66  779   89   94]\n",
      " [ 108   21   83  936   52]\n",
      " [  91   58   64   62  925]]\n",
      "\n",
      "\n",
      "Classification Report of the classifier: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     central       0.67      0.71      0.69      1200\n",
      "   halbLinks       0.84      0.84      0.84      1200\n",
      "  halbRechts       0.69      0.65      0.67      1200\n",
      "       links       0.77      0.78      0.78      1200\n",
      "      rechts       0.78      0.77      0.77      1200\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.75      0.75      0.75      6000\n",
      "weighted avg       0.75      0.75      0.75      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifier(lr, X_train_bi, X_test_bi, y_train_enc, y_test_enc, label, target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...using trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best') \n",
      "\n",
      "\n",
      "\n",
      "Accuracy of the classifier:     \n",
      "0.7416666666666667\n",
      "\n",
      "\n",
      "Confusion Matrix of the classifier: \n",
      "\n",
      "[[ 835   49  130  107   79]\n",
      " [  38 1010   51   38   63]\n",
      " [ 174   78  718  110  120]\n",
      " [  85   32   79  954   50]\n",
      " [  79   51   83   54  933]]\n",
      "\n",
      "\n",
      "Classification Report of the classifier: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     central       0.69      0.70      0.69      1200\n",
      "   halbLinks       0.83      0.84      0.83      1200\n",
      "  halbRechts       0.68      0.60      0.64      1200\n",
      "       links       0.76      0.80      0.77      1200\n",
      "      rechts       0.75      0.78      0.76      1200\n",
      "\n",
      "    accuracy                           0.74      6000\n",
      "   macro avg       0.74      0.74      0.74      6000\n",
      "weighted avg       0.74      0.74      0.74      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifier(dt, X_train_tri, X_test_tri, y_train_enc, y_test_enc, label, target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the classifier: BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "\n",
      "\n",
      "Accuracy of the classifier:     \n",
      "0.586\n",
      "\n",
      "\n",
      "Confusion Matrix of the classifier: \n",
      "\n",
      "[[674  28 442  20  36]\n",
      " [ 65 783 276  14  62]\n",
      " [213  53 859  12  63]\n",
      " [226  13 449 462  50]\n",
      " [ 90  68 287  17 738]]\n",
      "\n",
      "\n",
      "Classification Report of the classifier: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     central       0.53      0.56      0.55      1200\n",
      "   halbLinks       0.83      0.65      0.73      1200\n",
      "  halbRechts       0.37      0.72      0.49      1200\n",
      "       links       0.88      0.39      0.54      1200\n",
      "      rechts       0.78      0.61      0.69      1200\n",
      "\n",
      "    accuracy                           0.59      6000\n",
      "   macro avg       0.68      0.59      0.60      6000\n",
      "weighted avg       0.68      0.59      0.60      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifier(nb, X_train_tri, X_test_tri, y_train_enc, y_test_enc, label, target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the classifier: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) \n",
      "\n",
      "\n",
      "\n",
      "Accuracy of the classifier:     \n",
      "0.8008333333333333\n",
      "\n",
      "\n",
      "Confusion Matrix of the classifier: \n",
      "\n",
      "[[ 895   39  123   90   53]\n",
      " [  40 1064   33   22   41]\n",
      " [ 144   69  822   89   76]\n",
      " [  63   14   65 1018   40]\n",
      " [  59   41   59   35 1006]]\n",
      "\n",
      "\n",
      "Classification Report of the classifier: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     central       0.75      0.75      0.75      1200\n",
      "   halbLinks       0.87      0.89      0.88      1200\n",
      "  halbRechts       0.75      0.69      0.71      1200\n",
      "       links       0.81      0.85      0.83      1200\n",
      "      rechts       0.83      0.84      0.83      1200\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.80      0.80      0.80      6000\n",
      "weighted avg       0.80      0.80      0.80      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifier(svc, X_train_tri, X_test_tri, y_train_enc, y_test_enc, label, target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "\n",
      "\n",
      "Accuracy of the classifier:     \n",
      "0.752\n",
      "\n",
      "\n",
      "Confusion Matrix of the classifier: \n",
      "\n",
      "[[ 858   41  150   94   57]\n",
      " [  44 1015   55   28   58]\n",
      " [ 178   65  774   90   93]\n",
      " [ 107   21   82  935   55]\n",
      " [  90   59   60   61  930]]\n",
      "\n",
      "\n",
      "Classification Report of the classifier: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     central       0.67      0.71      0.69      1200\n",
      "   halbLinks       0.85      0.85      0.85      1200\n",
      "  halbRechts       0.69      0.65      0.67      1200\n",
      "       links       0.77      0.78      0.78      1200\n",
      "      rechts       0.78      0.78      0.78      1200\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.75      0.75      0.75      6000\n",
      "weighted avg       0.75      0.75      0.75      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifier(lr, X_train_tri, X_test_tri, y_train_enc, y_test_enc, label, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
